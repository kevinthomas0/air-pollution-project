{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbab0548",
   "metadata": {},
   "source": [
    "# Approximate Graph Propagation v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import requests\n",
    "from os import makedirs, path, listdir, remove\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import zipfile as zpf\n",
    "from shutil import rmtree\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import squareform, pdist, cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "\n",
    "import httplib2\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86195f6",
   "metadata": {},
   "source": [
    "## Get LAQN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a303b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"SO2\"\n",
    "region = \"London\"\n",
    "start_date = \"1996-01-01\"\n",
    "end_date = \"2021-01-01\"\n",
    "folder='tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00997ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LAQN data\n",
    "laqn_df = pd.read_csv(path.join(folder, f\"LAQN_{species}_{start_date}_{end_date}.csv\"), index_col=\"date\", infer_datetime_format=True)\n",
    "print(laqn_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93539ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load map file\n",
    "london_boroughs_gdf = gpd.read_file(path.join(folder, \"london_boroughs_coordinates.shp\"))\n",
    "london_gdf = london_boroughs_gdf.dissolve()\n",
    "print(london_boroughs_gdf.shape)\n",
    "london_boroughs_gdf.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LAQN metadata\n",
    "london_sites_gdf = gpd.read_file(path.join(folder, \"LAQN_sites.shp\"))\n",
    "print(london_sites_gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7233767",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_sites_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0447b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_on_map(data_geodataframe, map_geodataframe, \n",
    "                data_column=None, map_column=None, \n",
    "                data_cmap=None, map_cmap=None, \n",
    "                data_color=None, map_color=\"whitesmoke\", \n",
    "                data_markersize=0.1, \n",
    "                map_edge_color=\"black\", \n",
    "                colorbar=False, \n",
    "                title=\"Greater London\", \n",
    "                fontsize=\"25\", \n",
    "                figsize=(20,10), \n",
    "                axis=\"off\",\n",
    "                mark=None):\n",
    "    \n",
    "    base = data_geodataframe.plot(column=data_column, \n",
    "                           ax=map_geodataframe.plot(column=map_column, \n",
    "                                                    figsize=figsize, \n",
    "                                                    color=map_color, \n",
    "                                                    edgecolor=map_edge_color, \n",
    "                                                    cmap=map_cmap), \n",
    "                           color=data_color, cmap=data_cmap, markersize=data_markersize)\n",
    "    if colorbar:\n",
    "        colorbar_max = data_geodataframe[data_column].max()\n",
    "        norm = plt.Normalize(data_geodataframe[data_column].min(), colorbar_max)\n",
    "        plt.colorbar(plt.cm.ScalarMappable(cmap=data_cmap, \n",
    "        norm=norm)).set_label(data_column)\n",
    "        \n",
    "    if mark:\n",
    "        marked = data_geodataframe[data_geodataframe['@SiteCode'] == mark]\n",
    "        marked.plot(ax=base, marker='x', color='black', markersize=15);\n",
    "    \n",
    "    plt.suptitle(title, fontsize=fontsize)\n",
    "    plt.xlabel('Longitude', fontsize=14)\n",
    "    plt.ylabel('Latitude', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.axis(axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954774e",
   "metadata": {},
   "source": [
    "## Graph Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.orig = self.df.copy()\n",
    "        self.df['date'] = pd.to_datetime(self.df.date)\n",
    "        \n",
    "    def drop_null(self, nan_percent):\n",
    "        # drop column if proportion of NaN elements exceed the nan_percent\n",
    "        min_count = int(((100-nan_percent)/100)*self.df.shape[0] + 1)\n",
    "        return self.df.dropna(axis=1, thresh=min_count) \n",
    "        \n",
    "    def fill_mean(self):\n",
    "        return self.df.fillna(self.df.mean())\n",
    "    \n",
    "    def group(self, freq):\n",
    "        # group the data by the specified freq (month/year) and average across this period, then fill NaN values \n",
    "        df = self.df.groupby(pd.Grouper(key=\"date\", freq=freq)).mean()\n",
    "        return df\n",
    "    \n",
    "    def group_and_fill(self, freq):\n",
    "        # group the data by the specified freq (month/year) and average across this period, then fill NaN values \n",
    "        df = self.df.groupby(pd.Grouper(key=\"date\", freq=freq)).mean()\n",
    "        return df.ffill().bfill()\n",
    "    \n",
    "    def fill(self):\n",
    "        df = self.df.copy()\n",
    "        for col in df.columns.drop('date'):\n",
    "            df[col] = df[col].fillna(df.groupby([df.date.dt.year, df.date.dt.month])[col].transform('mean'))\n",
    "        return df.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeAM():\n",
    "    def __init__(self, df):\n",
    "        am_shape = (df.shape[1], df.shape[1])\n",
    "        self.am = pd.DataFrame(np.zeros(shape=am_shape), columns=df.columns, index=df.columns)\n",
    "    \n",
    "    def euclidean_dist(self, df):\n",
    "        # np.linalg.norm(complete['TD0'].values - complete['BG3'].values) #test euclidean distance between two columns\n",
    "        dist_arr = squareform(pdist(df.transpose()))\n",
    "        return pd.DataFrame(dist_arr, columns=df.columns.unique(), index=df.columns.unique())\n",
    "    \n",
    "    def cosine_dist(self, df):\n",
    "        dist_arr = cosine_similarity(df.transpose())\n",
    "        np.fill_diagonal(dist_arr, 0)\n",
    "        return pd.DataFrame(dist_arr, columns=df.columns.unique(), index=df.columns.unique())\n",
    "    \n",
    "    def threshold_euclidean(self, df, threshold):\n",
    "        for col in df.columns:\n",
    "#             df.loc[df[col] > threshold, col] = 0\n",
    "#             df.loc[df[col] < threshold, col] = 1\n",
    "            df[col] = np.where(df[col]>=threshold, 0, 1)\n",
    "        np.fill_diagonal(df.values, 0)\n",
    "        return df\n",
    "    \n",
    "    def diagonal_degree(self, df):\n",
    "        diag_series = np.diag(df.sum())\n",
    "        degree_mat = pd.DataFrame(diag_series, columns=df.columns.unique(), index=df.columns.unique())\n",
    "        return degree_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7938a",
   "metadata": {},
   "source": [
    "## (a) Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(\"tmp/LAQN_NO2_1996-01-01_2021-01-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.group('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68083603",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.isna().sum().sum() / (9133 * 201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99104bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set(df, num_valid_values=500):\n",
    "    max_size = 0\n",
    "    max_index = 0\n",
    "\n",
    "    for i in range(0, df.shape[0], 5):\n",
    "        test = df.iloc[i:].isnull()\n",
    "        test.reset_index(drop=True, inplace=True)\n",
    "        res = test.eq(True).idxmax()\n",
    "        size = res[res > num_valid_values].size\n",
    "        if size > max_size:\n",
    "            max_size = size\n",
    "            max_index = i\n",
    "\n",
    "    test = df.iloc[max_index:].isnull()\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "    res = test.eq(True).idxmax()\n",
    "    max_cols = res[res > num_valid_values].keys()\n",
    "    test_set = df[max_cols].iloc[max_index:max_index+num_valid_values]\n",
    "    return test_set, max_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7962778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set, max_cols = get_test_set(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc62661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_gaps(test_set, num_gaps=2000, seed=0):\n",
    "    np.random.seed(0)\n",
    "    testing = test_set.copy()\n",
    "\n",
    "    # Replace random entries with NaNs\n",
    "    num_entries = test_set.size # 14000 (500 * 28)\n",
    "    nan_indices = np.random.choice(np.arange(num_entries), num_gaps, replace=False)\n",
    "    nan_entries = [(num // test_set.shape[1], num % test_set.shape[1]) for num in nan_indices]\n",
    "\n",
    "    initial = []\n",
    "    for entry in nan_entries:\n",
    "        initial.append(testing.iloc[entry])\n",
    "        testing.iloc[entry] = np.nan\n",
    "    return nan_entries, initial, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f0de93",
   "metadata": {},
   "source": [
    "## Graph Propagation Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da700f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPropagation():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def threshold_am(self, df, threshold):\n",
    "        result = df.copy()\n",
    "        for col in result.columns:\n",
    "#             df.loc[df[col] > threshold, col] = 0\n",
    "#             df.loc[df[col] < threshold, col] = 1\n",
    "            result[col] = np.where(result[col] >= threshold, 1, 0)\n",
    "        np.fill_diagonal(result.values, 1)\n",
    "        return result\n",
    "    \n",
    "    def diagonal_degree(self, df):\n",
    "        diag_series = np.diag(df.sum())\n",
    "        result = pd.DataFrame(diag_series, columns=df.columns.unique(), index=df.columns.unique())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH PROPAGATION ALGORITHM\n",
    "\n",
    "def D_pow(mat, power):\n",
    "    return scipy.linalg.fractional_matrix_power(mat, power)\n",
    "\n",
    "# w = [0.8, 0.2]\n",
    "\n",
    "def basic_graph_propagation(X, A, w, L, a=0.5, b=0.5):\n",
    "    D_list = np.sum(A, axis=1) # D matrix\n",
    "    w = np.array(w) \n",
    "    prop_matrix = np.diag(D_list**-a).dot(A).dot(np.diag(D_list**-b)) # DAD^(-1)\n",
    "    prop_matrix = np.nan_to_num(prop_matrix) # convert NaNs to 0s\n",
    "    \n",
    "    pi = np.zeros_like(X)\n",
    "    r = X\n",
    "    for i in range(L):\n",
    "        Y_i = w[i:].sum()\n",
    "        Y_iplus = w[i+1:].sum()\n",
    "        \n",
    "        # update pi estimate\n",
    "        q = (w[i]/Y_i) * r\n",
    "        pi += q\n",
    "        \n",
    "        # update r\n",
    "        r = (Y_i/Y_iplus) * prop_matrix.dot(r.T).T\n",
    "        \n",
    "    q = w[L]/w[L:].sum() * r\n",
    "    pi += q\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_refactor(gap_data):\n",
    "    filled_data = gap_data.ffill().bfill()\n",
    "    am = ComputeAM(filled_data)\n",
    "    euclidean_am = am.euclidean_dist(filled_data)\n",
    "\n",
    "    mean = euclidean_am.mean().mean()\n",
    "    refactored = (mean / euclidean_am)\n",
    "    np.fill_diagonal(refactored.values, 0)\n",
    "    return filled_data, refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b752fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_L(matrix):\n",
    "    total = np.zeros_like(matrix)\n",
    "    \n",
    "    i = 0\n",
    "    while np.count_nonzero(total) != matrix.size:\n",
    "        i += 1\n",
    "        total += np.linalg.matrix_power(matrix, i)\n",
    "        if i == 10:\n",
    "            break\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d405645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_progation_matrix(data, euclideans, threshold, L=None, alpha=None, w=np.array([1, 0, 0, 0])):\n",
    "    prop = GraphPropagation()\n",
    "    A = prop.threshold_am(euclideans, threshold)\n",
    "\n",
    "    if alpha:\n",
    "        w = [alpha*(1-alpha)**i for i in range(10)]\n",
    "    if not L:\n",
    "        L = get_L(A)\n",
    "\n",
    "    # Apply algorithm\n",
    "    array_data = data.to_numpy()\n",
    "    Z = basic_graph_propagation(array_data, A, w, L)\n",
    "    return Z, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a82811",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "[alpha*(1-alpha)**i for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9496d03",
   "metadata": {},
   "source": [
    "### Compute Error - Individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c5cfd",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "* alpha: determines weight of each hop\n",
    "* threshold: determine which edges are 1s and 0s\n",
    "* L: # of hops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eae129",
   "metadata": {},
   "source": [
    "Variables:\n",
    "* testing - test dataset with forced gaps\n",
    "* initial - list of initial readings for gaps\n",
    "* nan_entries - indices of forced gap entries\n",
    "* filled_data - test dataset forward and backward filled\n",
    "* euclidean - similarity matrix formed from euclidean distance metric\n",
    "* A - adjacency matrix formed from thresholding euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3e0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_error(initial, final):\n",
    "    return np.linalg.norm(np.array(initial) - np.array(final)) / len(initial)**0.5\n",
    "\n",
    "def absolute_error(initial, final):\n",
    "    return np.mean(np.absolute(np.array(initial) - np.array(final)))\n",
    "\n",
    "def smape_error(initial, final):\n",
    "    initial, final = np.array(initial), np.array(final)\n",
    "    num = np.absolute(initial - final)\n",
    "    den = (np.absolute(initial) + np.absolute(final)) / 2\n",
    "    elems = num/den\n",
    "    return np.sum(elems) / elems.size\n",
    "\n",
    "def compute_alpha_error(alpha, threshold, L, initial, nan_entries, data, euclideans, error_type='rmse'):\n",
    "    prop = GraphPropagation()\n",
    "    A = prop.threshold_am(euclideans, threshold)\n",
    "    w = [alpha*(1-alpha)**i for i in range(10)]\n",
    "\n",
    "    # Apply algorithm\n",
    "    array_data = data.to_numpy()\n",
    "    Z = basic_graph_propagation(array_data, A, w, L)\n",
    "    \n",
    "    final = []\n",
    "    for entry in nan_entries:\n",
    "        final.append(Z[entry])\n",
    "        \n",
    "    if error_type == 'rmse':\n",
    "        error = rmse_error(initial, final)\n",
    "    elif error_type == 'absolute':\n",
    "        error = absolute_error(initial, final)\n",
    "    \n",
    "    return error\n",
    "\n",
    "def compute_threshold_error(threshold, alpha, L, initial, nan_entries, data, euclideans, error_type='rmse'):\n",
    "    prop = GraphPropagation()\n",
    "    A = prop.threshold_am(euclideans, threshold)\n",
    "    w = [alpha*(1-alpha)**i for i in range(10)]\n",
    "\n",
    "    # Apply algorithm\n",
    "    array_data = data.to_numpy()\n",
    "    Z = basic_graph_propagation(array_data, A, w, L)\n",
    "    \n",
    "    final = []\n",
    "    for entry in nan_entries:\n",
    "        final.append(Z[entry])\n",
    "    \n",
    "    if error_type == 'rmse':\n",
    "        error = rmse_error(initial, final)\n",
    "    elif error_type == 'absolute':\n",
    "        error = absolute_error(initial, final)\n",
    "    \n",
    "    return error\n",
    "\n",
    "def compute_hop_error(L, alpha, threshold, initial, nan_entries, data, euclideans, error_type='rmse'):\n",
    "    L = int(round(L))\n",
    "    \n",
    "    prop = GraphPropagation()\n",
    "    A = prop.threshold_am(euclideans, threshold)\n",
    "    w = [alpha*(1-alpha)**i for i in range(10)]\n",
    "\n",
    "    # Apply algorithm\n",
    "    array_data = data.to_numpy()\n",
    "    Z = basic_graph_propagation(array_data, A, w, L)\n",
    "    \n",
    "    final = []\n",
    "    for entry in nan_entries:\n",
    "        final.append(Z[entry])\n",
    "    \n",
    "    if error_type == 'rmse':\n",
    "        error = rmse_error(initial, final)\n",
    "    elif error_type == 'absolute':\n",
    "        error = absolute_error(initial, final)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff236a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_entries, initial, testing = force_gaps(test_set, num_gaps=2000, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d28f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_data, euclidean = fill_and_refactor(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03191215",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.mean().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbf58a",
   "metadata": {},
   "source": [
    "# -----------------------------------------\n",
    "# RMSE Metric\n",
    "# -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fdfeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise alpha\n",
    "\n",
    "res_alpha = minimize(compute_alpha_error, 0.5, args=(1.1, 1, initial, nan_entries, filled_data, euclidean))\n",
    "print(res_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_alpha_error(0.2124, 1.5, 2, initial, nan_entries, filled_data, euclidean)\n",
    "compute_threshold_error(1.06, 0.2218, 2, initial, nan_entries, filled_data, euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_alpha = 0.3792\n",
    "# t_hop = 1\n",
    "# t_threshold = 1.07\n",
    "# # error - 409.517\n",
    "\n",
    "t_alpha = 0.2218\n",
    "t_hop = 2\n",
    "t_threshold = 1.06\n",
    "# error  - 8.96\n",
    "\n",
    "# # HOURLY\n",
    "# t_alpha = 0.216\n",
    "# t_hop = 2\n",
    "# t_threshold = 1.66\n",
    "# # error - 8.3583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c054af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise alpha\n",
    "\n",
    "plt.figure(1)\n",
    "alpha_err = []\n",
    "alpha_range = np.linspace(0.0, 0.6, 101)\n",
    "for alpha in alpha_range:\n",
    "    err = compute_alpha_error(alpha, t_threshold, t_hop, initial, nan_entries, filled_data, euclidean)\n",
    "    alpha_err.append(err)\n",
    "plt.plot(alpha_range, alpha_err)\n",
    "plt.title('RMSE Error', fontsize=18)\n",
    "plt.xlabel('Alpha', fontsize=14)\n",
    "plt.ylabel('Error', fontsize=14)\n",
    "\n",
    "plt.figure(2)\n",
    "hop_err = []\n",
    "hop_range = np.arange(1, 6)\n",
    "for L in hop_range:\n",
    "    err = compute_hop_error(L, t_alpha, t_threshold, initial, nan_entries, filled_data, euclidean)\n",
    "    hop_err.append(err)\n",
    "plt.plot(hop_range, hop_err)\n",
    "plt.title('RMSE Error', fontsize=18)\n",
    "plt.xlabel('Hops', fontsize=14)\n",
    "plt.ylabel('Error', fontsize=14)\n",
    "\n",
    "\n",
    "plt.figure(3)\n",
    "threshold_err = []\n",
    "threshold_range = np.linspace(1.0, 2.0, 101)\n",
    "for threshold in threshold_range:\n",
    "    err = compute_threshold_error(threshold, t_alpha, t_hop, initial, nan_entries, filled_data, euclidean)\n",
    "    threshold_err.append(err)\n",
    "plt.plot(threshold_range, threshold_err)\n",
    "plt.title('RMSE Error', fontsize=18)\n",
    "plt.xlabel('Threshold', fontsize=14)\n",
    "plt.ylabel('Error', fontsize=14)\n",
    "\n",
    "alpha_err = np.nan_to_num(alpha_err, nan=np.inf)\n",
    "print('Alpha error: ', min(alpha_err), alpha_range[np.argmin(alpha_err)])\n",
    "print('Hops error: ', min(hop_err), hop_range[np.argmin(hop_err)])\n",
    "print('Threshold error: ', min(threshold_err), threshold_range[np.argmin(threshold_err)])\n",
    "print(min(alpha_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9385dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t_alpha = 0.2218\n",
    "t_hop = 2\n",
    "t_threshold = 1.06\n",
    "'''\n",
    "\n",
    "Z, A = compute_progation_matrix(filled_data, euclidean, threshold=t_threshold, L=t_hop, alpha=t_alpha)\n",
    "final = []\n",
    "for entry in nan_entries:\n",
    "    final.append(Z[entry])\n",
    "\n",
    "x = np.arange(100)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(initial, final)\n",
    "plt.plot(x, x, color='black')\n",
    "plt.title(r'Algorithm evaluation (RMSE = 8.96)')\n",
    "plt.xlabel(r'True NO$_2$ concentration ($\\mu g/mm^3$)')\n",
    "plt.ylabel(r'Propagated NO$_2$ concentration ($\\mu g/mm^3$)')\n",
    "\n",
    "compute_alpha_error(0.222, 1.06, 2, initial, nan_entries, filled_data, euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t_alpha = 0.3792\n",
    "t_hop = 1\n",
    "t_threshold = 1.07\n",
    "# error - 409.517\n",
    "'''\n",
    "\n",
    "Z2, A2 = compute_progation_matrix(filled_data, euclidean, threshold=1.07, L=1, alpha=0.3792)\n",
    "final2 = []\n",
    "for entry in nan_entries:\n",
    "    final2.append(Z2[entry])\n",
    "\n",
    "x = np.arange(100)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(initial, final2)\n",
    "plt.plot(x, x, color='black')\n",
    "plt.title(r'Algorithm evaluation (RMSE = 9.16)')\n",
    "plt.xlabel(r'True NO$_2$ concentration ($\\mu g/mm^3$)')\n",
    "plt.ylabel(r'Propagated NO$_2$ concentration ($\\mu g/mm^3$)')\n",
    "\n",
    "compute_alpha_error(0.3792, 1.07, 1, initial, nan_entries, filled_data, euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t_alpha = 0.12212779\n",
    "t_hop = 3\n",
    "t_threshold = 1.06\n",
    "# error - 9.225\n",
    "'''\n",
    "\n",
    "Z2, A2 = compute_progation_matrix(filled_data, euclidean, threshold=1.06, L=3, alpha=0.122)\n",
    "final2 = []\n",
    "for entry in nan_entries:\n",
    "    final2.append(Z2[entry])\n",
    "\n",
    "x = np.arange(100)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(initial, final2)\n",
    "plt.plot(x, x, color='black')\n",
    "plt.title(r'Algorithm evaluation (RMSE = 9.23)')\n",
    "plt.xlabel(r'True NO$_2$ concentration ($\\mu g/mm^3$)')\n",
    "plt.ylabel(r'Propagated NO$_2$ concentration ($\\mu g/mm^3$)')\n",
    "\n",
    "compute_alpha_error(0.122, 1.06, 3, initial, nan_entries, filled_data, euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final)):\n",
    "    print(f'{initial[i]} -> {final[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03a03d",
   "metadata": {},
   "source": [
    "### Computer Error - Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3027d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(params, initial, nan_entries, data, euclideans, error_type='rmse'):\n",
    "    alpha = params[0]\n",
    "    threshold = params[1]\n",
    "    L = int(params[2])\n",
    "    \n",
    "    prop = GraphPropagation()\n",
    "    A = prop.threshold_am(euclideans, threshold)\n",
    "    w = [alpha*(1-alpha)**i for i in range(10)]\n",
    "\n",
    "    # Apply algorithm\n",
    "    array_data = data.to_numpy()\n",
    "    Z = basic_graph_propagation(array_data, A, w, L)\n",
    "    \n",
    "    final = []\n",
    "    for entry in nan_entries:\n",
    "        final.append(Z[entry])\n",
    "        \n",
    "    if error_type == 'rmse':\n",
    "        error = rmse_error(initial, final)\n",
    "    elif error_type == 'absolute':\n",
    "        error = absolute_error(initial, final)\n",
    "    elif error_type == 'smape':\n",
    "        error = smape_error(initial, final)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error([0.2, 1.5, 2], initial, nan_entries, filled_data, euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(compute_error, [0.5, 1.06, 3], args=(initial, nan_entries, filled_data, euclidean))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bc66a",
   "metadata": {},
   "source": [
    "## Comparison Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e74d1",
   "metadata": {},
   "source": [
    "TEST:\n",
    "* seed = 1\n",
    "* alpha = 0.2218\n",
    "* threshold = 1.06\n",
    "* L = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error against alpha and threshold\n",
    "plt.figure(1)\n",
    "\n",
    "alpha_range = np.linspace(0.1, 0.5, 50)\n",
    "threshold_range = np.linspace(0.5, 2.0, 16)\n",
    "L_range = np.arange(1, 6)\n",
    "\n",
    "loss = np.zeros((len(alpha_range), len(threshold_range)))\n",
    "for i, val1 in enumerate(alpha_range): \n",
    "    for j, val2 in enumerate(threshold_range):\n",
    "        val1 = round(val1, 2)\n",
    "        val2 = round(val2, 2)\n",
    "        \n",
    "        t_hop = 3\n",
    "        loss[i][j] = compute_alpha_error(val1, val2, t_hop, initial, nan_entries, filled_data, euclidean)\n",
    "        \n",
    "X, Y = np.meshgrid(threshold_range, alpha_range)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(X[:50], Y[:50], loss[:50], cmap='plasma', linewidth=2)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel('threshold', fontsize=12)\n",
    "ax.set_ylabel('alpha', fontsize=12)\n",
    "ax.set_zlabel('error', fontsize=12)\n",
    "\n",
    "shape = np.unravel_index(loss.argmin(), loss.shape)\n",
    "print(f'Threshold: {X[shape]}')\n",
    "print(f'Alpha: {Y[shape]}')\n",
    "print(f'Error: {np.min(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20453261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss against alpha and L (hops)\n",
    "\n",
    "alpha_range = np.linspace(0.1, 0.5, 50)\n",
    "threshold_range = np.linspace(0.5, 2.0, 16)\n",
    "L_range = np.arange(1, 6)\n",
    "\n",
    "loss = np.zeros((len(alpha_range), len(L_range)))\n",
    "for i, val1 in enumerate(alpha_range): \n",
    "    for j, val2 in enumerate(L_range):\n",
    "        val1 = round(val1, 2)\n",
    "        val2 = round(val2, 2)\n",
    "        \n",
    "        t_threshold = 1.1\n",
    "        loss[i][j] = compute_alpha_error(val1, t_threshold, val2, initial, nan_entries, filled_data, euclidean)\n",
    "        \n",
    "X, Y = np.meshgrid(L_range, alpha_range)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "lim1 = 50\n",
    "lim2 = 4\n",
    "surf = ax.plot_surface(X[:lim1, :lim2], Y[:lim1, :lim2], loss[:lim1, :lim2], cmap='plasma', linewidth=2)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel('L (hops)', fontsize=12)\n",
    "ax.set_ylabel('alpha', fontsize=12)\n",
    "ax.set_zlabel('error', fontsize=12)\n",
    "\n",
    "shape = np.unravel_index(loss.argmin(), loss.shape)\n",
    "print(f'Hops: {X[shape]}')\n",
    "print(f'Alpha: {Y[shape]}')\n",
    "print(f'Error: {np.min(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ff6e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot loss against threshold and L (hops)\n",
    "\n",
    "alpha_range = np.linspace(0.1, 1.0, 10)\n",
    "threshold_range = np.linspace(0.5, 2.0, 160)\n",
    "L_range = np.arange(1, 6)\n",
    "\n",
    "loss = np.zeros((len(threshold_range), len(L_range)))\n",
    "for i, val1 in enumerate(threshold_range): \n",
    "    for j, val2 in enumerate(L_range):\n",
    "        val1 = round(val1, 2)\n",
    "        val2 = round(val2, 2)\n",
    "        \n",
    "        t_alpha = 0.222\n",
    "        loss[i][j] = compute_alpha_error(t_alpha, val1, val2, initial, nan_entries, filled_data, euclidean)\n",
    "        \n",
    "X, Y = np.meshgrid(L_range, threshold_range)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "lim1 = len(threshold_range)\n",
    "lim2 = len(L_range)\n",
    "surf = ax.plot_surface(X[:lim1, :lim2], Y[:lim1, :lim2], loss[:lim1, :lim2], cmap='plasma', linewidth=2)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('L (hops)')\n",
    "ax.set_ylabel('threshold')\n",
    "ax.set_zlabel('error')\n",
    "\n",
    "shape = np.unravel_index(loss.argmin(), loss.shape)\n",
    "print(f'Hops: {X[shape]}')\n",
    "print(f'Threshold: {Y[shape]}')\n",
    "print(f'Error: {np.min(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b893281",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee8c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_error([0.12, 1.3, 3], initial, nan_entries, filled_data, euclidean, error_type='rmse'))\n",
    "print(compute_error([0.22, 1.3, 2], initial, nan_entries, filled_data, euclidean, error_type='rmse'))\n",
    "print(compute_error([0.22, 1.1, 2], initial, nan_entries, filled_data, euclidean, error_type='rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_err = compute_error([0.2218, 1.06, 2], initial, nan_entries, filled_data, euclidean, error_type='rmse')\n",
    "smape_err = compute_error([0.2218, 1.06, 2], initial, nan_entries, filled_data, euclidean, error_type='smape')\n",
    "print(f'RMSE Error: {rmse_err}')\n",
    "print(f'SMAPE Error: {smape_err}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7655bb",
   "metadata": {},
   "source": [
    "## Scale to full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a70f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data, similarity = fill_and_refactor(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865232ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data\n",
    "am = ComputeAM(full_data)\n",
    "euclidean_am = am.euclidean_dist(full_data)\n",
    "euclidean_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t_alpha = 0.2218\n",
    "t_hop = 2\n",
    "t_threshold = 1.06\n",
    "'''\n",
    "\n",
    "Z, A = compute_progation_matrix(full_data, similarity, threshold=1.06, L=2, alpha=0.2218)\n",
    "# Z2 = compute_progation_matrix(full_data, similarity, threshold=0.7, L=1, alpha=0.4)\n",
    "\n",
    "# HOURLY\n",
    "# Z, A = compute_progation_matrix(full_data, similarity, threshold=1.66, L=2, alpha=0.216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7fa7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = np.copy(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, column) in enumerate(grouped):\n",
    "    for (j, entry) in enumerate(np.asarray(grouped[column])): \n",
    "        if not np.isnan(entry):\n",
    "            corrected[j][i] = entry\n",
    "#     print(np.count_nonzero(np.isnan(np.asarray(grouped[column]))))\n",
    "#     break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c77e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected == Z\n",
    "# print(grouped.isna().sum().sum())\n",
    "# print(grouped.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98f6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get similarity matrix from propagated data\n",
    "\n",
    "corrected_df = pd.DataFrame(corrected, columns=grouped.columns.unique(), index=grouped.index.unique())\n",
    "fd1, similarity = fill_and_refactor(corrected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "propagated_df = pd.DataFrame(corrected, columns = grouped.columns.unique(), index = grouped.index.unique())\n",
    "propagated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10168fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_dataframe(df, freq='M'):\n",
    "    grouped_df = df.copy() \n",
    "    grouped_df = grouped_df.reset_index(level=0)\n",
    "    grouped_df['date'] = pd.to_datetime(grouped_df.date)\n",
    "    grouped_df = grouped_df.groupby(pd.Grouper(key=\"date\", freq=freq)).mean()\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acebb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# propagated_df.to_csv('complete_NO2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = [0, 25, 50, 75, 100, 125, 150, 175, 200]\n",
    "vals = [np.array(similarity.columns)[i] for i in inds] \n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e8050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sim_heat = np.fill_diagonal(similarity.values, 3)\n",
    "plt.imshow(similarity, cmap='magma', interpolation='nearest', vmin=0, vmax=3)\n",
    "plt.title('Similarity Heat Map')\n",
    "plt.xticks(plt.xticks()[0][1:10], labels=vals[:9], fontsize=9)\n",
    "plt.yticks(plt.yticks()[0][1:10], labels=vals[:9], fontsize=9)\n",
    "# print(plt.xticks()[0].size)\n",
    "plt.tick_params(top=True, labeltop=True)\n",
    "plt.tick_params(bottom=False, labelbottom=False)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556842f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sim_heat = np.fill_diagonal(similarity.values, 3)\n",
    "plt.imshow(similarity/3, cmap='magma', interpolation='nearest', vmin=0, vmax=1)\n",
    "plt.title('Similarity Heat Map')\n",
    "plt.xticks(plt.xticks()[0][1:10], labels=vals[:9], fontsize=9)\n",
    "plt.yticks(plt.yticks()[0][1:10], labels=vals[:9], fontsize=9)\n",
    "# print(plt.xticks()[0].size)\n",
    "plt.tick_params(top=True, labeltop=True)\n",
    "plt.tick_params(bottom=False, labelbottom=False)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c674e92",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e614d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f450dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"NO2\"\n",
    "region = \"London\"\n",
    "start_date = \"1996-01-01\"\n",
    "end_date = \"2021-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4691a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LAQN site codes\n",
    "url_sites = f\"http://api.erg.kcl.ac.uk/AirQuality/Information/MonitoringSites/GroupName={region}/Json\"\n",
    "               \n",
    "london_sites = requests.get(url_sites)\n",
    "sites_df = pd.DataFrame(london_sites.json()['Sites']['Site'])\n",
    "site_codes = sites_df[\"@SiteCode\"].tolist()\n",
    "print(len(site_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sites for each local authority\n",
    "site_map = {} # map between local authority codes and list of sites belonging to that local authority\n",
    "location_map = {} # map between local authority codes and local authority names\n",
    "# local_codes = set(sites_df['@LocalAuthorityCode'].unique()) # 1 - 33\n",
    "for i in range(1, 34):\n",
    "    code = str(i)\n",
    "    location_map[code] = sites_df[sites_df['@LocalAuthorityCode'] == code]['@LocalAuthorityName'].unique()[0]\n",
    "    res = sites_df[sites_df['@LocalAuthorityCode'] == code]['@SiteCode']\n",
    "    site_map[code] = []\n",
    "    for j, site in res.items():\n",
    "        site_map[code].append(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8220a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "propagated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d357e",
   "metadata": {},
   "source": [
    "## Time Series Plots (grouped by day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = propagated_df.index.values\n",
    "stations = {'TD0', 'EN5', 'BN1', 'SK2', 'KC2', 'HI2'}\n",
    "while len(stations) < 10:\n",
    "    sample = np.random.choice(data.df.columns.values[1:], 1)[0]\n",
    "    stations.add(sample)\n",
    "    \n",
    "for index, station in enumerate(stations):\n",
    "    plt.figure(index, figsize=(12, 4))\n",
    "    plt.plot(dates, propagated_df[station].values, color='black', linestyle='dotted')\n",
    "    plt.plot(dates, grouped[station].values, color='black')\n",
    "    plt.title(f'Station: {station}')\n",
    "    plt.xlabel('date', fontsize=10)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = propagated_df.index.values\n",
    "stations = {'TD0', 'EN5', 'BN1', 'SK2', 'KC2', 'HI2', 'ME1'}\n",
    "while len(stations) < 10:\n",
    "    sample = np.random.choice(data.df.columns.values[1:], 1)[0]\n",
    "    stations.add(sample)\n",
    "\n",
    "start = 2000\n",
    "add = 300\n",
    "for index, station in enumerate(stations):\n",
    "    plt.figure(index, figsize=(12, 4))\n",
    "    plt.plot(dates[start:start+add], propagated_df[station].values[start:start+add], color='black', linestyle='dotted')\n",
    "    plt.plot(dates[start:start+add], grouped[station].values[start:start+add], color='black')\n",
    "    plt.title(f'Station: {station}')\n",
    "    plt.xlabel('date', fontsize=10)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b0d6c",
   "metadata": {},
   "source": [
    "## Time Series Plots (grouped by week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a900311",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_W = group_dataframe(grouped, 'W')\n",
    "propagated_df_W = group_dataframe(propagated_df, 'W')\n",
    "# grouped_W\n",
    "propagated_df_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fed07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = propagated_df_W.index.values\n",
    "stations = {'TD0', 'EN5', 'BN1', 'SK2', 'KC2', 'HI2'}\n",
    "while len(stations) < 10:\n",
    "    sample = np.random.choice(data.df.columns.values[1:], 1)[0]\n",
    "    stations.add(sample)\n",
    "    \n",
    "for index, station in enumerate(stations):\n",
    "    plt.figure(index, figsize=(12, 4))\n",
    "    plt.plot(dates, propagated_df_W[station].values, color='black', linestyle='dotted')\n",
    "    plt.plot(dates, grouped_W[station].values, color='black')\n",
    "    plt.title(f'Station: {station}')\n",
    "    plt.xlabel('date', fontsize=10)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88847e1",
   "metadata": {},
   "source": [
    "## Time Series Plots (grouped by month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_M = group_dataframe(grouped, 'M')\n",
    "propagated_df_M = group_dataframe(propagated_df, 'M')\n",
    "grouped_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = propagated_df_M.index.values\n",
    "\n",
    "### Find dates where months have missing data\n",
    "missing_dates = grouped.loc[pd.isna(grouped['TD0']), :].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b42fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET MISSING DATA PER MONTH\n",
    "\n",
    "years = np.arange(1996, 2021)\n",
    "months = np.arange(1, 13)\n",
    "\n",
    "def missing_data_count(df):\n",
    "    grouped_M = group_dataframe(df, 'M')\n",
    "    res = pd.DataFrame(index=grouped_M.index, columns=grouped_M.columns)\n",
    "    \n",
    "    stations = df.columns.tolist()\n",
    "    test = df.reset_index(level=0)\n",
    "    \n",
    "    i = 0\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            sample_df = test[(test['date'].dt.year == year) & (test['date'].dt.month == month)]\n",
    "            res.iloc[i] = sample_df.isna().sum().tolist()[1:]\n",
    "            i += 1\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_missing_dates(df, station):\n",
    "    station_data = df[station]\n",
    "    grouped_missing = station_data[station_data.isnull()]\n",
    "    grouped_missing.iloc[:] = 1.0\n",
    "    grouped_M_missing = group_dataframe(grouped_missing, 'M')\n",
    "    test = grouped_M_missing.reset_index(level=0)\n",
    "    missing_dates = test[test[station] == 1.0]['date'].tolist()\n",
    "    return missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_count = missing_data_count(grouped)\n",
    "# res.to_csv('random.csv')\n",
    "\n",
    "missing_dates = get_missing_dates(grouped, 'TD0')\n",
    "propagated_df_M['TD0'][missing_dates].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcdf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = propagated_df_M.index.values\n",
    "stations = {'TD0', 'EN5', 'BN1', 'SK2', 'KC2', 'HI2', 'RI2', 'WM6', 'EA1'}\n",
    "while len(stations) < 20:\n",
    "    sample = np.random.choice(data.df.columns.values[1:], 1)[0]\n",
    "    stations.add(sample)\n",
    "    \n",
    "for index, station in enumerate(stations):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(dates, propagated_df_M[station].values, color='black', linestyle='dotted')\n",
    "    plt.plot(dates, grouped_M[station].values, color='black')\n",
    "    plt.title(f'Station: {station}')\n",
    "    plt.xlabel('date', fontsize=12)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=12)\n",
    "    plt.xticks(fontsize=11)\n",
    "    plt.yticks(fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2963593",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = propagated_df_M.index.values\n",
    "stations = {'TD0', 'EN5', 'BN1', 'SK2', 'KC2', 'HI2', 'RI2'}\n",
    "while len(stations) < 10:\n",
    "    sample = np.random.choice(data.df.columns.values[1:], 1)[0]\n",
    "    stations.add(sample)\n",
    "    \n",
    "for index, station in enumerate(stations):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "#     plt.plot(dates, propagated_df_M[station].values, color='black', linestyle='dotted')\n",
    "    plt.plot(dates, grouped_M[station].values, color='black')\n",
    "    plt.plot(dates, [np.nanmean(grouped_M[station].values)]*301 , color='red', alpha= 0.0)\n",
    "    plt.title(f'Station: {station}')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=12)\n",
    "    plt.xticks(fontsize=11)\n",
    "    plt.yticks(fontsize=11)\n",
    "#     plt.xlim(date(1996, 1, 1), date(2021, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5c7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8566eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates = propagated_df_M.index.values\n",
    "stations = {'TD0', 'EN5', 'BN1', 'SK2', 'KC2', 'HI2'}\n",
    "while len(stations) < 20:\n",
    "    sample = np.random.choice(data.df.columns.values[1:], 1)[0]\n",
    "    stations.add(sample)\n",
    "    \n",
    "for index, station in enumerate(stations):\n",
    "    plt.figure(2*index, figsize=(12, 4))\n",
    "    plt.plot(dates, propagated_df_M[station].values, color='black', linestyle='dotted')\n",
    "    plt.plot(dates, grouped_M[station].values, color='black')\n",
    "    \n",
    "    missing_dates = get_missing_dates(grouped, station)\n",
    "    plt.scatter(missing_dates, propagated_df_M[station][missing_dates].values, marker='o', color='r', s = 3.0)\n",
    "    \n",
    "    plt.title(f'Station: {station}')\n",
    "    plt.xlabel('date', fontsize=10)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=10)\n",
    "    \n",
    "    plt.figure(2*index+1, figsize=(12, 4))\n",
    "    plt.scatter(dates, propagated_df_M[station].values, c=miss_count[station].values, marker='o', s=5.0, cmap='viridis')\n",
    "    plt.title(f'Station: {station}')\n",
    "    plt.xlabel('date', fontsize=10)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=10)\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ef3a5",
   "metadata": {},
   "source": [
    "### Borough Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced83ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfafa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cycle = [x['color'] for x in plt.rcParams['axes.prop_cycle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfaff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = propagated_df_M.index.values\n",
    "for i in range(1, 34):\n",
    "    code = str(i)\n",
    "    cols = [site for site in site_map[code] if site in propagated_df_M.columns]\n",
    "#     for col in cols\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for j, col in enumerate(cols):\n",
    "        color = prop_cycle[j % len(prop_cycle)]\n",
    "        plt.plot(dates, grouped_M[col].values, color=color, label=f'{col}', linewidth=1)\n",
    "        plt.plot(dates, propagated_df_M[col].values, color=color, linestyle='dashed', linewidth=1)\n",
    "    plt.title(f'{location_map[code]}', fontsize=13)\n",
    "    plt.ylabel(\"NO$_{2}$ Concentrations (µg/m$^3$)\", fontsize=11)\n",
    "    plt.xlabel(\"Date\", fontsize=11)\n",
    "    plt.legend()\n",
    "    \n",
    "    #     ax = propagated_df_M[cols].plot(figsize=(10, 4), title=f'{location_map[code]}', fontsize=5)\n",
    "#     ax.set_title(f'{location_map[code]}', fontsize=13)\n",
    "#     ax.set_ylabel(\"NO$_{2}$ Concentrations (µg/m$^3$)\", fontsize=11)\n",
    "#     ax.set_xlabel(\"Date\", fontsize=11)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e9dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = propagated_df_M.index.values\n",
    "for i in range(1, 34):\n",
    "    code = str(i)\n",
    "    cols = [site for site in site_map[code] if site in propagated_df_M.columns]\n",
    "#     for col in cols\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for j, col in enumerate(cols):\n",
    "        color = prop_cycle[j % len(prop_cycle)]\n",
    "        plt.plot(dates, grouped_M[col].values, color=color, label=f'{col}', linewidth=1)\n",
    "#         plt.plot(dates, propagated_df_M[col].values, color=color, linestyle='dashed', linewidth=1)\n",
    "    plt.title(f'{location_map[code]}', fontsize=13)\n",
    "    plt.ylabel(\"NO$_{2}$ Concentrations (µg/m$^3$)\", fontsize=12)\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "    plt.xticks(fontsize=11)\n",
    "    plt.yticks(fontsize=11)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56f4ab",
   "metadata": {},
   "source": [
    "### Similar Station Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_stations = {}\n",
    "for station in A.columns:\n",
    "    similar_stations[station] = similarity[station].sort_values(ascending=False)[:5].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_cycle = prop_cycle = [x['color'] for x in plt.rcParams['axes.prop_cycle']]\n",
    "plotted_stations = set()\n",
    "\n",
    "i = 0\n",
    "for station, similars in similar_stations.items():\n",
    "    plotted_stations.add(station)\n",
    "    \n",
    "    plt.figure(i, figsize=(12, 4))\n",
    "    plt.plot(dates, propagated_df_M[station].values, label=station, color=colour_cycle[0])\n",
    "    for j, similar in enumerate(similars):\n",
    "        plt.plot(dates, propagated_df_M[similar].values, label=similar, color=colour_cycle[j+1])\n",
    "    plt.title(f'Similar stations to {station}')\n",
    "    plt.xlabel('date', fontsize=10)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=10)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(i+1, figsize=(12, 4))\n",
    "    plt.plot(dates, grouped_M[station].values, label=station, color=colour_cycle[0])\n",
    "    for j, similar in enumerate(similars):\n",
    "        plt.plot(dates, grouped_M[similar].values, label=similar, color=colour_cycle[j+1])\n",
    "    plt.xlabel('date', fontsize=10)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=10)\n",
    "    plt.legend()\n",
    "    \n",
    "    i += 2\n",
    "    if i == 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e270c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_cycle = prop_cycle = [x['color'] for x in plt.rcParams['axes.prop_cycle']]\n",
    "plotted_stations = set()\n",
    "\n",
    "i = 0\n",
    "for station, similars in similar_stations.items():\n",
    "    plotted_stations.add(station)\n",
    "    \n",
    "    plt.figure(i, figsize=(12, 4))\n",
    "#     plt.plot(dates, grouped_M[station].values, color=colour_cycle[0], label=f'{station}', linewidth=1)\n",
    "#     plt.plot(dates, propagated_df_M[station].values, color=colour_cycle[0], linestyle='dashed', linewidth=1)\n",
    "    for j, similar in enumerate(similars):\n",
    "        plt.plot(dates, grouped_M[similar].values, color=colour_cycle[j+1], label=f'{similar}', linewidth=1)\n",
    "        plt.plot(dates, propagated_df_M[similar].values, color=colour_cycle[j+1], linestyle='dashed', linewidth=1)\n",
    "#         plt.plot(dates, propagated_df_M[similar].values, label=similar, color=colour_cycle[j+1])\n",
    "#     plt.title(f\"Stations similar to: '{station}'\")\n",
    "    plt.xlabel('date', fontsize=10)\n",
    "    plt.ylabel('NO$_{2}$ Concentrations (µg/m$^3$)', fontsize=10)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(i+1)\n",
    "    similarity_list = similarity[station]\n",
    "    london_sites_gdf_sim = london_sites_gdf.copy()\n",
    "    london_sites_gdf_sim['Similarity'] = np.nan\n",
    "    for index, sim_val in similarity_list.items():\n",
    "        london_sites_gdf_sim.loc[london_sites_gdf_sim['@SiteCode'] == index, 'Similarity'] = sim_val\n",
    "    london_sites_gdf_sim = london_sites_gdf_sim[~london_sites_gdf_sim['Similarity'].isna()]\n",
    "\n",
    "    plot_on_map(london_sites_gdf_sim, london_gdf, data_column='Similarity', colorbar=True,\n",
    "                title=f\"Similarity map: '{station}'\", \n",
    "                data_markersize=5, fontsize=15,\n",
    "                map_edge_color=\"gray\", figsize=(15,7), axis=\"on\", mark=station)\n",
    "    \n",
    "    \n",
    "    i += 2\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d115ae",
   "metadata": {},
   "source": [
    "## Plot similar stations on land use map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67971441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LAQN metadata\n",
    "london_landuse = gpd.read_file(path.join(folder, \"gis_osm_landuse_a_free_1.shp\"))\n",
    "print(london_landuse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_landuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "london_landuse.plot(figsize=(10,10), column='fclass', legend=True, legend_kwds={'loc': 'center right', 'bbox_to_anchor':(1.3,0.5)})\n",
    "plt.title('Greater London Land-use Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_palette = {\n",
    "    'allotments': '#002fff',\n",
    "    'cemetery': 'gray',\n",
    "    'commercial': 'orange',\n",
    "    'farmland': '#002fff',\n",
    "    'farmyard': '#002fff',\n",
    "    'forest': 'green',\n",
    "    'grass': 'green',\n",
    "    'heath': 'green',\n",
    "    'industrial': '#4B0092',\n",
    "    'meadow': 'green',\n",
    "    'military': '#4B0092',\n",
    "    'nature_reserve': 'green',\n",
    "    'orchard': 'pink',\n",
    "    'park': 'green',\n",
    "    'quarry': 'gray',\n",
    "    'recreation_ground': 'green',\n",
    "    'residential': '#E3E3E3',\n",
    "    'retail': 'orange',\n",
    "    'scrub': 'green',\n",
    "}\n",
    "cmap = matplotlib.colors.ListedColormap([color for key, color in land_palette.items()])\n",
    "\n",
    "london_landuse.plot(figsize=(10,10), column='fclass', legend=True, cmap=cmap, legend_kwds={'loc': 'center right', 'bbox_to_anchor':(1.3,0.5)})\n",
    "plt.title('Greater London Land-use Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be528f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_on_osm_map(data_geodataframe, map_geodataframe, cmap, figsize=(20,10), colorbar=False, data_column='Similarity', title='LAQN Monitoring Station Distribution', mark=None, similars=None):\n",
    "    \n",
    "    base = data_geodataframe.plot(ax=map_geodataframe.plot(figsize=figsize, \n",
    "                                           column='fclass',\n",
    "                                           legend=False,\n",
    "                                           cmap=cmap,\n",
    "                                           alpha=0.5,\n",
    "                                           legend_kwds={'loc': 'center right', 'bbox_to_anchor':(1.3,0.5)}),\n",
    "                    color='black', marker='x', markersize=75, linewidths=3)\n",
    "    \n",
    "    if colorbar:\n",
    "        colorbar_max = data_geodataframe[data_column].max()\n",
    "        norm = plt.Normalize(data_geodataframe[data_column].min(), colorbar_max)\n",
    "        plt.colorbar(plt.cm.ScalarMappable(cmap=None, \n",
    "        norm=norm)).set_label(data_column)\n",
    "        \n",
    "    if mark:\n",
    "        marked = data_geodataframe[data_geodataframe['@SiteCode'] == mark]\n",
    "        marked.plot(ax=base, marker='o', color='black', markersize=100);\n",
    "\n",
    "    if mark and similar:\n",
    "        title = f'{title}\\n Similar stations: {similars}'\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20)\n",
    "    plt.xlabel('Longitude', fontsize=14)\n",
    "    plt.ylabel('Latitude', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.axis(\"on\")\n",
    "    plt.savefig(f'images/{mark}_similarity.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c8c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Get similarity maps\n",
    "\n",
    "# for station, similars in similar_stations.items():\n",
    "#     similarity_list = similarity[station]\n",
    "#     london_sites_gdf_sim = london_sites_gdf.copy()\n",
    "#     london_sites_gdf_sim['Similarity'] = np.nan\n",
    "#     for index, sim_val in similarity_list.items():  \n",
    "#         #ensure current station is most similar\n",
    "#         if index == station:\n",
    "#             london_sites_gdf_sim.loc[london_sites_gdf_sim['@SiteCode'] == index, 'Similarity'] = 100\n",
    "#         else:\n",
    "#             london_sites_gdf_sim.loc[london_sites_gdf_sim['@SiteCode'] == index, 'Similarity'] = sim_val\n",
    "        \n",
    "#     london_sites_gdf_sim = london_sites_gdf_sim[~london_sites_gdf_sim['Similarity'].isna()]\n",
    "    \n",
    "#     # MAP N MOST SIMILAR STATIONS\n",
    "# #     data_count=10\n",
    "# #     london_sites_gdf_sim = london_sites_gdf_sim.sort_values(by='Similarity', ascending=False)[:data_count]\n",
    "    \n",
    "#     # ... OR MAP STATIONS > 0.9*MAX\n",
    "#     max_similarity = london_sites_gdf_sim.sort_values(by='Similarity', ascending=False).iloc[1]['Similarity']\n",
    "#     london_sites_gdf_sim = london_sites_gdf_sim.loc[(london_sites_gdf_sim['Similarity'] >= 0.9*max_similarity)]\n",
    "      \n",
    "#     similars = london_sites_gdf_sim['@SiteCode'].values\n",
    "#     similars = np.setdiff1d(similars, station)\n",
    "#     plot_on_osm_map(london_sites_gdf_sim[:11], london_landuse, cmap, mark=station, title=f'LAQN NO$_2$ Dataset - Station {station}', similars=similars[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fca8c6",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe45af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find stations in common: WA7 == WA8, LB4, KC5, WM6 == WMZ, NB1\n",
    "\n",
    "stations = ['CD4', 'CD5', 'WA7', 'WA8', 'WM6', 'WMZ', 'CD9', 'KT3', 'NB1']\n",
    "for i in stations:\n",
    "    test = london_sites_gdf[london_sites_gdf['@SiteCode'] == i]\n",
    "    plot_on_osm_map(test, london_landuse, cmap, title = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23021c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(similarity).sort_values(ascending=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555018b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd967ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of similar stations over all stations\n",
    "similar_station_count = {}\n",
    "\n",
    "for station in A.columns:\n",
    "    data_count = 10\n",
    "    similars = similarity[station].sort_values(ascending=False)[:data_count].index.tolist()\n",
    "    \n",
    "    if station == 'TD0':\n",
    "        print(similars)\n",
    "    \n",
    "    for i in similars:\n",
    "        if i not in similar_station_count:\n",
    "            similar_station_count[i] = 0\n",
    "        similar_station_count[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b152572",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_station_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc1a63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stations = ['CD4', 'CD5']\n",
    "grouped[stations].to_csv('random.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
